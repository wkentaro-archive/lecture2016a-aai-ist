{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune pre-trained networks\n",
    "We will fine-tune a pre-trained network (CaffeNet) on the Caltech-101 dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup configuration files\n",
    "* Copy prototxt files from CaffeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ~/apps/caffe/models\n",
    "mkdir finetune_cal101\n",
    "cp bvlc_reference_caffenet/*.prototxt finetune_cal101/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Edit solver.prototxt files for Caltech-101"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "net: \"models/finetune_cal101/train_val.prototxt\"  # specify network configuration file (be aware where 'caffe' command is called)\n",
    "\n",
    "#test_iter: 1000      # test_iter specifies how many forward passes the test should carry out.\n",
    "test_iter: 40         # we are using batch size 50 and test images are less than 2,000, so 40 iterations should be enough.\n",
    "\n",
    "#test_interval: 1000\n",
    "test_interval: 200\n",
    "\n",
    "#base_lr: 0.01        # initial learning rate\n",
    "base_lr: 0.001        # considering that most parts of the network is already trained, we decrease the initial learning rate\n",
    "\n",
    "lr_policy: \"step\"     # learning rate policy: drop the learning rate in \"steps\"\n",
    "gamma: 0.1\n",
    "stepsize: 100000      # drop the learning rate every 100K iterations\n",
    "display: 20\n",
    "\n",
    "#max_iter: 450000     # number of iterations in training     \n",
    "max_iter: 50000       # in fine-tuning, convergence is usually faster compared to that of full-scartch training \n",
    "\n",
    "momentum: 0.9\n",
    "weight_decay: 0.0005\n",
    "\n",
    "#snapshot: 10000\n",
    "snapshot: 1000        # take a snapshot (resume point) every 1000 iterations\n",
    "snapshot_prefix: \"models/finetune_cal101/caltech101_train\"   \n",
    "\n",
    "solver_mode: GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Next, edit train_val.txt, which describes the network configuration during training. Since we are going to fine-tune using raw images (unlike in the CaffeNet example), we have to change many specifications. We show some important points below. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "name: \"FinetuneCaltech101\"\n",
    "layer {             # input layer for training images\n",
    "  name: \"data\"\n",
    "  #type: \"Data\"     ### CHANGE ###\n",
    "  type: \"ImageData\" # we are using raw images instead of a database\n",
    "  top: \"data\"\n",
    "  top: \"label\"\n",
    "  include {\n",
    "    phase: TRAIN\n",
    "  }\n",
    "  transform_param {\n",
    "    mirror: true\n",
    "    crop_size: 227\n",
    "    mean_file: \"data/ilsvrc12/imagenet_mean.binaryproto\"   # mean image provided in Caffe\n",
    "  }\n",
    "# mean pixel / channel-wise mean instead of mean image\n",
    "#  transform_param {\n",
    "#    crop_size: 227\n",
    "#    mean_value: 104\n",
    "#    mean_value: 117\n",
    "#    mean_value: 123\n",
    "#    mirror: true\n",
    "#  }\n",
    "  image_data_param {    ### CHANGE ###\n",
    "    #source: \"examples/imagenet/ilsvrc12_train_lmdb\"      ### CHANGE ###\n",
    "    source: \"/home/ubuntu/dataset/Caltech101/train.txt\" # specify a text file listing training images\n",
    "    #batch_size: 256    ### CHANGE ###\n",
    "    batch_size: 50      # use smaller minibatch\n",
    "    new_height: 256     ### INSERT ###\n",
    "    new_width: 256      ### INSERT ###\n",
    "    #backend: LMDB      ### REMOVE ###  we are no more using a database\n",
    "  }\n",
    "}\n",
    "layer {             # input layer for training images\n",
    "  name: \"data\"\n",
    "  #type: \"Data\"     ### CHANGE ###\n",
    "  type: \"ImageData\" # we are using raw images instead of a database\n",
    "  top: \"data\"\n",
    "  top: \"label\"\n",
    "  include {\n",
    "    phase: TEST\n",
    "  }\n",
    "  ### change all other stuffs in the same manner as we did for training...\n",
    "  ...\n",
    "  ... \n",
    "}\n",
    "...\n",
    "...\n",
    "layer {\n",
    "  name: \"fc8_cal101\"      ### We need to define another layer compatible to the output of Caltech-101. \n",
    "                          ### We may simply edit original \"fc8\" layer.\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"fc7\"\n",
    "  top: \"fc8_cal101\"       ### CHANGE ###    \n",
    "  \n",
    "  ### lr_mult is set to higher than for other layers, because this layer is starting from random while the others are already trained\n",
    "  param {\n",
    "    #lr_mult: 1     ### CHANGE ###\n",
    "    lr_mult: 10\n",
    "    decay_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    #lr_mult: 2     ### CHANGE ###\n",
    "    lr_mult: 20\n",
    "    decay_mult: 0\n",
    "  }\n",
    "  inner_product_param {\n",
    "    num_output: 102       ### Caltech-101 has 102 categories.\n",
    "    weight_filler {\n",
    "      type: \"gaussian\"\n",
    "      std: 0.01\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "      value: 0\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"accuracy\"\n",
    "  type: \"Accuracy\"\n",
    "  bottom: \"fc8_cal101\"   ### Don't forget to edit other layers using the output of \"fc8_cal101\" layer.\n",
    "  bottom: \"label\"\n",
    "  top: \"accuracy\"\n",
    "  include {\n",
    "    phase: TEST\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"loss\"\n",
    "  type: \"SoftmaxWithLoss\"\n",
    "  bottom: \"fc8_cal101\"  ### Don't forget to edit other layers using the output of \"fc8_cal101\" layer.\n",
    "  bottom: \"label\"\n",
    "  top: \"loss\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fine-tune the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, everything is ready! Let's start fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "export LD_LIBRARY_PATH=\"/home/ubuntu/anaconda2/lib:$LD_LIBRARY_PATH\"\n",
    "cd ~/apps/caffe\n",
    "# ./build/tools/caffe shows the usage\n",
    "./build/tools/caffe train -solver models/finetune_cal101/solver.prototxt \\\n",
    "-weights models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel -gpu 0\n",
    "\n",
    "# -solver : define solver parameters\n",
    "# -weights : specify a pre-trained model (Optional for fine-tuning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After epochs, we got 84% validation accuracy."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "...\n",
    "...\n",
    "I1010 11:53:23.039369  1721 solver.cpp:228] Iteration 960, loss = 0.0105217\n",
    "I1010 11:53:23.039458  1721 solver.cpp:244]     Train net output #0: loss = 0.0105214 (* 1 = 0.0105214 loss)\n",
    "I1010 11:53:23.039477  1721 sgd_solver.cpp:106] Iteration 960, lr = 0.001\n",
    "I1010 11:53:31.213901  1721 solver.cpp:228] Iteration 980, loss = 0.016644\n",
    "I1010 11:53:31.213992  1721 solver.cpp:244]     Train net output #0: loss = 0.0166437 (* 1 = 0.0166437 loss)\n",
    "I1010 11:53:31.214011  1721 sgd_solver.cpp:106] Iteration 980, lr = 0.001\n",
    "I1010 11:53:38.978766  1721 solver.cpp:337] Iteration 1000, Testing net (#0)\n",
    "I1010 11:53:44.929672  1721 solver.cpp:404]     Test net output #0: accuracy = 0.84\n",
    "I1010 11:53:44.929764  1721 solver.cpp:404]     Test net output #1: loss = 0.708356 (* 1 = 0.708356 loss)\n",
    "I1010 11:53:45.073386  1721 solver.cpp:228] Iteration 1000, loss = 0.113219\n",
    "I1010 11:53:45.073473  1721 solver.cpp:244]     Train net output #0: loss = 0.113219 (* 1 = 0.113219 loss)\n",
    "I1010 11:53:45.073503  1721 sgd_solver.cpp:106] Iteration 1000, lr = 0.001\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that valication accuracy improves to 89.7% after 50,000 iterations, although it is difficult to confirm it on the iLect server due to resource limitation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using the fine-tuned network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can utilize our fine-tuned network in the same manner as in the previous exercise.\n",
    "To do this, we need to prepared \"deploy.txt\" that specifies the configurations for the final fixed network. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "name: \"FinetuneCaltech101\"\n",
    "...\n",
    "...\n",
    "layer {\n",
    "  name: \"fc8_cal101\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"fc7\"\n",
    "  top: \"fc8_cal101\"\n",
    "  inner_product_param {\n",
    "    num_output: 102\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"prob\"\n",
    "  type: \"Softmax\"\n",
    "  bottom: \"fc8_cal101\"\n",
    "  top: \"prob\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's call our fine-tuned network using python interface. Here, we use the snapshot after 1000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up Python environment: numpy for numerical routines, and matplotlib for plotting\n",
    "import sys,os\n",
    "import numpy as np\n",
    "\n",
    "# load caffe\n",
    "caffe_root = '/home/ubuntu/apps/caffe/'  # this file should be run from {caffe_root}/examples (otherwise change this line)\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "import caffe # If you get \"No module named _caffe\", either you have not built pycaffe or you have the wrong path.\n",
    "\n",
    "# load Caltech-101 labels\n",
    "labels_file = '/home/ubuntu/dataset/Caltech101/labels.txt'\n",
    "labels = np.loadtxt(labels_file, str, delimiter='\\t')\n",
    "\n",
    "caffe.set_mode_gpu()\n",
    "\n",
    "model_def = caffe_root + 'models/finetune_cal101/deploy.prototxt'\n",
    "model_weights = caffe_root + 'models/finetune_cal101/caltech101_train_iter_1000.caffemodel'\n",
    "\n",
    "net = caffe.Net(model_def,      # defines the structure of the model\n",
    "                model_weights,  # contains the trained weights\n",
    "                caffe.TEST)     # use test mode (e.g., don't perform dropout)\n",
    "\n",
    "(K,H,W) = net.blobs['data'].shape[1:] # input size\n",
    "\n",
    "# load the mean ImageNet image (as distributed with Caffe) for subtraction\n",
    "mu = np.load(caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy') # average image over the ImageNet dataset\n",
    "mu = caffe.io.resize_image(mu.transpose(1,2,0),(H,W)) # resize the average image\n",
    "mu = mu.transpose(2,0,1)\n",
    "#mu = mu.mean(1).mean(1)  # we may use average over pixels instead\n",
    "\n",
    "# create transformer for the input called 'data'\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "transformer.set_transpose('data', (2,0,1))  # move image channels to outermost dimension\n",
    "transformer.set_mean('data', mu)            # subtract the dataset-mean value in each channel\n",
    "transformer.set_raw_scale('data', 255)      # rescale from [0, 1] to [0, 255]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # swap channels from RGB to BGR\n",
    "\n",
    "image = caffe.io.load_image(caffe_root + 'examples/images/cat.jpg')\n",
    "transformed_image = transformer.preprocess('data', image)\n",
    "\n",
    "# copy the image data into the memory allocated for the net\n",
    "net.blobs['data'].data[...] = transformed_image # fill the batch with the same image...(i.e., 50 copies)\n",
    "### perform classification\n",
    "output = net.forward()\n",
    "output_prob = output['prob'][0]  # the output probability vector for the first image in the batch\n",
    "\n",
    "print 'predicted class is:', output_prob.argmax()\n",
    "print 'output label:', labels[output_prob.argmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Exercise\n",
    "* Setup prototxt files above.\n",
    "* Change some parameters and see what happenes (e.g., learning rate, batch size, solver type).\n",
    "* Compare with fixed feature based approach and full-scratch training. (Full-scartch training can be done by simply removing -weight option)\n",
    "* Train on other pre-trained network (VGG-16).\n",
    "* Use your own dataset!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
