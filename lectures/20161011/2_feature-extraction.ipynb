{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Caltech-101 with fixed pre-trained features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing Caltech-101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Download image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p ~/dataset/Caltech101  # dataset dir\n",
    "cd ~/dataset/Caltech101\n",
    "wget https://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz -qnc --no-check-certificate  # get image data\n",
    "tar xzf 101_ObjectCategories.tar.gz \n",
    "rm -rf images; mv 101_ObjectCategories images  # rename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Scan the dataset and setup training and testing splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "random.seed(20) # fix the seed (we randomly sample training and testing examples)\n",
    "\n",
    "dataset_dir = '/home/ubuntu/dataset/Caltech101/'\n",
    "labels = os.listdir(dataset_dir+'images/')\n",
    "train_list, val_list = [], []\n",
    "\n",
    "for c, category in enumerate(labels):\n",
    "    files = os.listdir(dataset_dir+'images/'+category)\n",
    "    random.shuffle(files)\n",
    "    for img in files[:30]:  # 30 training samples per class\n",
    "        train_list.append(dataset_dir+'images/'+category+'/'+img+' '+str(c))  # \"image_path category_id\" (following Caffe style)\n",
    "    for img in files[30:50]:  # at most 20 testing samples per class\n",
    "        val_list.append(dataset_dir+'images/'+category+'/'+img+' '+str(c))\n",
    "\n",
    "random.shuffle(train_list) # Be sure to shuffle training images (otherwise fine-tuning will fail)\n",
    "\n",
    "with open(dataset_dir+'train.txt', 'w') as f:\n",
    "    f.write('\\n'.join(train_list))\n",
    "with open(dataset_dir+'val.txt', 'w') as f:\n",
    "    f.write('\\n'.join(val_list))\n",
    "with open(dataset_dir+'labels.txt', 'w') as f:\n",
    "    f.write('\\n'.join(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setup pre-trained network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Just the same as in the previous exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# load caffe\n",
    "caffe_root = '/home/ubuntu/apps/caffe/'  # this file should be run from {caffe_root}/examples (otherwise change this line)\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "import caffe # If you get \"No module named _caffe\", either you have not built pycaffe or you have the wrong path.\n",
    "caffe.set_mode_gpu()\n",
    "\n",
    "# load a pre-trained model\n",
    "model_def = caffe_root + 'models/bvlc_reference_caffenet/deploy.prototxt'\n",
    "model_weights = caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'\n",
    "#model_def = caffe_root + 'models/VGG16/VGG_ILSVRC_16_layers_deploy.prototxt'\n",
    "#model_weights = caffe_root + 'models/VGG16/VGG_ILSVRC_16_layers.caffemodel'\n",
    "\n",
    "net = caffe.Net(model_def,      # defines the structure of the model\n",
    "                model_weights,  # contains the trained weights\n",
    "                caffe.TEST)     # use test mode (e.g., don't perform dropout)\n",
    "\n",
    "(K,H,W) = net.blobs['data'].shape[1:] # input size\n",
    "# load the mean ImageNet image (as distributed with Caffe) for subtraction\n",
    "mu = np.load(caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy')\n",
    "mu = caffe.io.resize_image(mu.transpose(1,2,0),(H,W))\n",
    "mu = mu.transpose(2,0,1)\n",
    "#mu = mu.mean(1).mean(1)  # average over pixels to obtain the mean (BGR) pixel values\n",
    "\n",
    "# create transformer for the input called 'data'\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "\n",
    "transformer.set_transpose('data', (2,0,1))  # move image channels to outermost dimension\n",
    "transformer.set_mean('data', mu)            # subtract the dataset-mean value in each channel\n",
    "transformer.set_raw_scale('data', 255)      # rescale from [0, 1] to [0, 255]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # swap channels from RGB to BGR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3. Extract features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bsize = 50 # mini batch size    \n",
    "(K,H,W) = net.blobs['data'].shape[1:] # input size\n",
    "net.blobs['data'].reshape(bsize, K,H,W)\n",
    "\n",
    "features = {'train':[],'val':[]}\n",
    "crits = {'train':[],'val':[]}\n",
    "\n",
    "for T in ['train', 'val']:\n",
    "    f = open(dataset_dir+T+'.txt','r')\n",
    "    lines = f.read().split('\\n')\n",
    "    f.close()\n",
    "    for idx, line in enumerate(lines):\n",
    "        imgpath, cat_id = line.rstrip().split(' ')\n",
    "        crits[T].append(int(cat_id))\n",
    "        image = caffe.io.load_image(imgpath)\n",
    "        transformed_image = transformer.preprocess('data', image)\n",
    "        net.blobs['data'].data[idx%bsize] = transformed_image\n",
    "        if (idx+1) % bsize == 0 or (idx+1) == len(lines):\n",
    "            net.forward() # feed forward\n",
    "            feat = np.copy(net.blobs['fc7'].data[:idx%bsize+1]) # use feature responses of a specific layer (let's change this!)\n",
    "            features[T].append(feat.reshape(feat.shape[0],-1)) # flatten feature matrix (for 'conv' layers)\n",
    "            print 'Feature extracted: ', T, '~',idx+1\n",
    "    \n",
    "    features[T] = np.vstack(features[T])\n",
    "    crits[T] = np.hstack(crits[T])\n",
    "    assert(features[T].shape[0]==crits[T].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "## train a linear SVM classifier\n",
    "clf = svm.LinearSVC(C=1) # you may need to change C\n",
    "clf.fit(features['train'],crits['train'])\n",
    "yPredTrain = clf.predict(features['train'])\n",
    "yPredTest = clf.predict(features['val'])\n",
    "\n",
    "print \"Training score: \", len((np.where(yPredTrain == crits['train'])[0]))*1.0/features['train'].shape[0]\n",
    "print \"Test(validation) score: \", len((np.where(yPredTest == crits['val'])[0]))*1.0/features['val'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exercise\n",
    "* Change the layer from which features are extracted and see how it affects the performance.\n",
    "* Change the pre-trained network to the VGG-16 model (and ResNet if possible)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
