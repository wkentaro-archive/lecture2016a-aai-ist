{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "# the CIFAR10 images are RGB\n",
    "img_channels = 3\n",
    "nb_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selector (Pick one from below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CIFAR 10\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "# trim the data\n",
    "X_train = X_train.astype('float32', order='C')\n",
    "X_test = X_test.astype('float32', order='C')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "data = X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Save as a pickle\n",
    "import pickle\n",
    "import gzip\n",
    "pickle.dump(data, gzip.open(\"data.pkl.gz\", \"wb\")) # save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## save to dir\n",
    "import os\n",
    "from scipy.misc import imsave\n",
    "\n",
    "if not os.path.exists('./images'):\n",
    "    os.makedirs('./images')\n",
    "\n",
    "for i in range(10):\n",
    "    if not os.path.exists('./train_images/%d/' % i):\n",
    "        os.makedirs('./train_images/%d/' % i)\n",
    "\n",
    "for i, (x, y) in enumerate(zip(X_train, y_train)):\n",
    "    imsave('./train_images/%d/%d.jpg' % (y, i), x)\n",
    "    imsave('./images/%d.jpg' % i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Save as LMDB\n",
    "import lmdb\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "env = lmdb.open('./data.lmdb', map_size=X_train.nbytes * 8)\n",
    "with env.begin(write=True, buffers=True) as txn:\n",
    "    for i, x in tqdm(enumerate(X_train)):\n",
    "        txn.put(str(i).encode('ascii'), x)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
