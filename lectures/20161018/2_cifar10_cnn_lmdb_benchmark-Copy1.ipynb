{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Train a simple deep CNN on the CIFAR10 small images dataset.\n",
    "GPU run command:\n",
    "    THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python cifar10_cnn.py\n",
    "It gets down to 0.65 test logloss in 25 epochs, and down to 0.55 after 50 epochs.\n",
    "(it's still underfitting at that point, though).\n",
    "Note: the data was pickled with Python 2, and some encoding issues might prevent you\n",
    "from loading it in Python 3. You might have to load it in Python 2,\n",
    "save it in a different format, load it in Python 3 and repickle it.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "\n",
    "batch_size = 32\n",
    "nb_classes = 10\n",
    "nb_epoch = 1\n",
    "data_augmentation = True\n",
    "img_shape = (32, 32, 3)\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "# the CIFAR10 images are RGB\n",
    "img_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = pickle.load(gzip.open(\"data.pkl.gz\", 'rb')) # use normal pickle / cPickle for unpacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='same',\n",
    "                        input_shape=img_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# let's train the model using SGD + momentum (how original).\n",
    "# sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "sgd = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minibatch Generators (Pick one below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Memory batch (Fast, of course)\n",
    "\n",
    "def get_batches():\n",
    "    batch_num = len(Y_train) // batch_size\n",
    "    for i in range(batch_num):\n",
    "        start = i * batch_size\n",
    "        end = (i + 1) * batch_size\n",
    "        batch_X = X_train[start: end]\n",
    "        batch_Y = Y_train[start: end]\n",
    "        batch_X = np.array(batch_X).astype('float32')\n",
    "        batch_Y = np.array(batch_Y)\n",
    "        yield batch_X, batch_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Directory batch (Very slow)\n",
    "import glob\n",
    "from scipy import misc\n",
    "\n",
    "def get_batches():\n",
    "    batch_num = len(Y_train) // batch_size\n",
    "    for i in range(batch_num):\n",
    "        start = i * batch_size\n",
    "        end = (i + 1) * batch_size\n",
    "        batch_X = [misc.imread(\"./images/%d.jpg\" % j) for j in range(start, end)]\n",
    "        batch_Y = Y_train[start: end]\n",
    "        batch_X = np.array(batch_X).astype('float32') / 255\n",
    "        batch_Y = np.array(batch_Y)\n",
    "        yield batch_X, batch_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## LMDB batch (Storage but fast)\n",
    "import lmdb\n",
    "import numpy as np\n",
    "\n",
    "def get_batches():\n",
    "    lmdb_env = lmdb.open('./data.lmdb')\n",
    "    lmdb_txn = lmdb_env.begin()\n",
    "    lmdb_cursor = lmdb_txn.cursor()\n",
    "    \n",
    "    batch_X, batch_Y = [], []\n",
    "    for i, (k, x) in enumerate(lmdb_cursor):\n",
    "        if len(batch_X) >= batch_size:\n",
    "            batch_X = np.array(batch_X).astype('float32')\n",
    "            batch_Y = np.array(batch_Y)\n",
    "            yield batch_X, batch_Y\n",
    "            batch_X, batch_Y = [], []\n",
    "        else:\n",
    "            batch_X.append(np.fromstring(x, dtype=np.float32).reshape(img_shape))\n",
    "            batch_Y.append(Y_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%snakeviz\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "num_batch_epoch = len(X_train) // batch_size\n",
    "for epoch in range(nb_epoch):\n",
    "    for x, y in tqdm(get_batches()):\n",
    "        model.train_on_batch(x, y)\n",
    "    print(model.evaluate(X_test, Y_test, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Advanced techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More about profilers;\n",
    "\n",
    "### Python profiler (CPU Time)\n",
    "\n",
    "\tpython -m cProfile -o profile.log cifar10_cnn.py\n",
    "\n",
    "### CUDA profiler\n",
    "\n",
    "* edit .theanorc -> profile=True\n",
    "* export CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "### Python profiler (Memory Usage)\n",
    "\n",
    "\tpython -m memory_profiler cifar10_cnn.py\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU-related commands.\n",
    "\n",
    "GPU Status;\n",
    "\n",
    "\n",
    "```\n",
    "$ nvidia-smi\n",
    "$ nvidia-smi -q\n",
    "$ watch nvidia-smi\n",
    "```\n",
    "\t\n",
    "Benchmark;\n",
    "\n",
    "```\n",
    "$ cp -Rf /usr/local/cuda/samples/ ~/\n",
    "$ cd ~/samples/0_Simple/matrixMul ; make\n",
    "$ ./matrixMul\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
